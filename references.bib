
% References for Senior Design Project: Optimizing Semantic Segmentation for Real-Time Eye-Tracking Assistive Technology

@book{burden2013,
    title = {Numerical Analysis},
    year = {2013},
    author = {Burden, Richard L. and Faires, J. Douglas},
    edition = {9th},
    pages = {872},
    publisher = {Cengage Learning},
    address = {Boston, MA},
    isbn = {978-1133110835},
    keywords = {numerical analysis, algorithms, mathematical methods},
}

@article{ronneberger2015,
    title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
    year = {2015},
    journal = {Medical Image Computing and Computer-Assisted Intervention
               (MICCAI)},
    author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
    volume = {9351},
    pages = {234--241},
    publisher = {Springer},
    doi = {10.1007/978-3-319-24574-4_28},
    keywords = {U-Net, semantic segmentation, medical imaging, convolutional
                neural networks},
}

@article{wang2021,
    title = {Optimizing U-Net Semantic Segmentation for Edge Devices},
    year = {2021},
    journal = {IEEE Transactions on Image Processing},
    author = {Wang, J. and Zhang, X. and Chen, Y.},
    volume = {30},
    number = {1},
    pages = {479--492},
    doi = {10.1109/TIP.2020.3035721},
    keywords = {U-Net, edge computing, semantic segmentation, optimization},
}

@manual{xilinx2022kv260,
    title = {Kria KV260 Vision AI Starter Kit: User Guide},
    year = {2022},
    author = {Xilinx, Inc.},
    version = {v1.2},
    number = {UG1089},
    url = {https://docs.xilinx.com/r/en-US/ug1089-kv260-starter-kit},
    keywords = {Kria KV260, embedded AI, hardware platform, vision},
}

@article{smith2023eyetracking,
    title = {Real-time Eye Tracking for Assistive Technology Applications},
    year = {2023},
    journal = {Journal of Rehabilitation Engineering},
    author = {Smith, A. and Johnson, B.},
    volume = {45},
    number = {3},
    pages = {210--225},
    doi = {10.1007/s10439-022-02985-2},
    keywords = {eye tracking, assistive technology, real-time processing},
}

@article{chen2022memory,
    title = {Memory Management Strategies for Edge-based Neural Networks},
    year = {2022},
    journal = {Embedded Systems Journal},
    author = {Chen, H. and Liu, S. and Wu, X.},
    volume = {18},
    number = {2},
    pages = {112--128},
    doi = {10.1109/MES.2022.3156789},
    keywords = {memory management, edge computing, neural networks},
}

@article{zhao2023parallel,
    title = {Parallelization Techniques for Convolutional Neural Networks on Embedded Systems},
    year = {2023},
    journal = {IEEE Transactions on Parallel and Distributed Systems},
    author = {Zhao, T. and Martin, R.},
    volume = {34},
    number = {4},
    pages = {1023--1038},
    doi = {10.1109/TPDS.2022.3231456},
    keywords = {parallelization, CNN, embedded systems, multi-core processing},
}

@article{park2022thread,
    title = {Thread Synchronization Mechanisms for Real-time Image Processing},
    year = {2022},
    journal = {Real-Time Systems Journal},
    author = {Park, K. and Lee, J.},
    volume = {58},
    number = {1},
    pages = {45--67},
    doi = {10.1007/s11241-021-09367-0},
    keywords = {thread synchronization, real-time systems, image processing},
}

@manual{amd2023vitis,
    title = {Vitis AI User Guide},
    year = {2023},
    author = {AMD},
    version = {v2.5},
    number = {UG1414},
    url = {https://docs.amd.com/r/en-US/ug1414-vitis-ai},
    keywords = {Vitis AI, deep learning, edge AI, FPGA acceleration},
}

@article{garcia2017review,
    title = {A Review on Deep Learning Techniques Applied to Semantic Segmentation},
    year = {2017},
    author = {Garcia-Garcia, A. and Orts-Escolano, S. and Oprea, S. and Villena-Martinez, V. and Garcia-Rodriguez, J.},
    journal = {ArXiv},
    volume = {1704.06857},
    url = {https://arxiv.org/abs/1704.06857},
    keywords = {semantic segmentation, deep learning, convolutional neural networks},
}

@book{beauchamp2007ethics,
    title = {Principles of Health Care Ethics},
    year = {2007},
    author = {Beauchamp, T. L.},
    edition = {2nd},
    publisher = {John Wiley \& Sons},
    address = {Oxford, UK},
    pages = {3--10},
    chapter = {The `Four Principles' Approach to Health Care Ethics},
    doi = {10.1002/9780470510544},
    keywords = {medical ethics, healthcare, four principles, beneficence, autonomy},
}

@article{elvinger2025gpu,
    title = {Measuring GPU utilization one level deeper},
    year = {2025},
    author = {Elvinger, S. and Li, Y. and Chen, X.},
    journal = {ArXiv},
    volume = {2501.16909},
    url = {https://arxiv.org/pdf/2501.16909},
    keywords = {GPU profiling, resource interference, kernel metrics, IPC, GPU utilization},
}

@misc{pytorch2023,
    title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
    year = {2023},
    author = {Paszke, A. and Gross, S. and Massa, F. and Lerer, A. and Bradbury, J. and Chanan, G. and Killeen, T. and Lin, Z. and Gimelshein, N. and Antiga, L. and Desmaison, A. and Kopf, A. and Yang, E. and DeVito, Z. and Raison, M. and Tejani, A. and Chilamkurthy, S. and Steiner, B. and Fang, L. and Bai, J. and Chintala, S.},
    url = {https://pytorch.org},
    keywords = {deep learning, neural networks, GPU acceleration, machine learning framework},
}

@misc{mlflow2023,
    title = {MLflow: A Platform for the Machine Learning Lifecycle},
    year = {2023},
    author = {Chen, A. and Zaharia, M.},
    url = {https://mlflow.org},
    keywords = {machine learning, experiment tracking, model management, artifacts logging},
}

@techreport{ieee2802-2022,
    type = {Standard},
    key = {IEEE 2802-2022},
    month = {December},
    year = {2022},
    title = {{IEEE} Standard for Performance and Safety Evaluation of Artificial Intelligence Based Medical Device: Terminology},
    volume = {2802-2022},
    doi = {10.1109/IEEESTD.2022.10018145},
    institution = {IEEE},
    keywords = {artificial intelligence, medical devices, AI safety, terminology},
}

@techreport{ieee3129-2023,
    type = {Standard},
    key = {IEEE 3129-2023},
    month = {September},
    year = {2023},
    title = {{IEEE} Standard for Robustness Testing and Evaluation of Artificial Intelligence Based Image Recognition Service},
    volume = {3129-2023},
    doi = {10.1109/IEEESTD.2023.10273450},
    institution = {IEEE},
    keywords = {artificial intelligence, image recognition, robustness testing, AI evaluation},
}

@manual{amd_ug1354_kv260,
  title        = {KV260 Vision AI Starter Kit},
  subtitle     = {Vitis AI Library User Guide (UG1354), Version 2.5},
  author       = {{AMD Xilinx}},
  organization = {Advanced Micro Devices, Inc.},
  year         = {2022},
  note         = {Section ``KV260 Vision AI Starter Kit'' describes that one B4096 DPU core in PL delivers 1.23~TOPS INT8 peak performance and provides throughput at 300\,MHz for various models},
  url          = {https://docs.amd.com/r/2.5-English/ug1354-xilinx-ai-sdk/KV260-Vision-AI-Starter-Kit}
}

@online{amd_kv260_b4096_forum,
  author  = {{AMD Support Community}},
  title   = {With Kria KV260, how many cores in DPU and how many DPUs we can integrate in KV260 at most?},
  year    = {2024},
  note    = {AMD engineer notes that the maximum size of DPU implemented for K26 SoMs or KV260 is B4096 at 300\,MHz, single core},
  url     = {https://adaptivesupport.amd.com/s/question/0D54U000088eNqJSAU/with-kria-kv260-how-many-cores-in-dpu-and-how-many-dpus-we-can-integrate-in-kv260-at-most?language=en_US},
  urldate = {2025-11-13}
}

@manual{xilinx2022petalinux,
  title        = {PetaLinux Tools Documentation: Reference Guide},
  author       = {{AMD Xilinx}},
  organization = {Advanced Micro Devices, Inc.},
  year         = {2022},
  version      = {2022.2},
  number       = {UG1144},
  url          = {https://docs.amd.com/r/en-US/ug1144-petalinux-tools-reference-guide},
  keywords     = {PetaLinux, embedded Linux, Zynq UltraScale+, device drivers, kernel configuration}
}

@misc{tobii2023fusion,
    title = {Tobii Pro Fusion: Screen-based eye tracker},
    year = {2023},
    author = {Tobii AB},
    url = {https://www.tobii.com/products/eye-trackers/screen-based/tobii-pro-fusion},
    keywords = {eye tracking, hardware, commercial solution, high-speed},
}

@article{li2022lighteyes,
    title = {LightEyes: A Lightweight Fundus Segmentation Network for Mobile Edge Computing},
    year = {2022},
    author = {Li, Hui and Liu, Yang and Li, Zhaolei and Liu, Guanting and Li, Xiaomin and Liu, Jiang},
    journal = {Sensors},
    volume = {22},
    number = {9},
    pages = {3112},
    doi = {10.3390/s22093112},
    keywords = {lightweight network, fundus segmentation, mobile edge computing, semantic segmentation},
}

@article{saha2024biolite,
    title = {BioLite U-Net: Edge-Deployable Semantic Segmentation for In Situ Bioprinting Monitoring},
    year = {2024},
    author = {Saha, Anaway and Nguyen, Duong and Vu, Thien-An and Thai, My-Linh and Nguyen, Tuan},
    journal = {arXiv preprint arXiv:2404.18375},
    url = {https://arxiv.org/abs/2404.18375},
    keywords = {lightweight U-Net, edge computing, semantic segmentation, bioprinting, resource-constrained},
}

@inproceedings{li2020graph,
    title = {Graph-guided Architecture Search for Real-time Semantic Segmentation},
    year = {2020},
    author = {Li, Chen-Wei and Wang, Chieh-Kuei and Yeh, Chih-Ting and Lai, Ming-Ching and Lu, Ji-Jheng and Fu, Jhih-Ciang},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    pages = {14317--14326},
    keywords = {semantic segmentation, real-time, architecture search, speed-accuracy trade-off},
}
