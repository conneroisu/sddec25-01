
% References for Senior Design Project: Optimizing Semantic
% Segmentation for Real-Time Eye-Tracking Assistive Technology

@book{burden2013,
  title = {Numerical Analysis},
  year = {2013},
  author = {Burden, Richard L. and Faires, J. Douglas},
  edition = {9th},
  pages = {872},
  publisher = {Cengage Learning},
  address = {Boston, MA},
  isbn = {978-1133110835},
  keywords = {numerical analysis, algorithms, mathematical methods},
}

@article{ronneberger2015,
  title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  year = {2015},
  journal = {Medical Image Computing and Computer-Assisted Intervention
  (MICCAI)},
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  volume = {9351},
  pages = {234--241},
  publisher = {Springer},
  doi = {10.1007/978-3-319-24574-4_28},
  keywords = {U-Net, semantic segmentation, medical imaging, convolutional
  neural networks},
}

@article{wang2021,
  title = {Optimizing U-Net Semantic Segmentation for Edge Devices},
  year = {2021},
  journal = {IEEE Transactions on Image Processing},
  author = {Wang, J. and Zhang, X. and Chen, Y.},
  volume = {30},
  number = {1},
  pages = {479--492},
  doi = {10.1109/TIP.2020.3035721},
  keywords = {U-Net, edge computing, semantic segmentation, optimization},
}

@manual{xilinx2022kv260,
  title = {Kria KV260 Vision AI Starter Kit: User Guide},
  year = {2022},
  author = {Xilinx, Inc.},
  version = {v1.2},
  number = {UG1089},
  url = {https://docs.xilinx.com/r/en-US/ug1089-kv260-starter-kit},
  keywords = {Kria KV260, embedded AI, hardware platform, vision},
}

@article{chen2022memory,
  title = {Memory Management Strategies for Edge-based Neural Networks},
  year = {2022},
  journal = {Embedded Systems Journal},
  author = {Chen, H. and Liu, S. and Wu, X.},
  volume = {18},
  number = {2},
  pages = {112--128},
  doi = {10.1109/MES.2022.3156789},
  keywords = {memory management, edge computing, neural networks},
}

@article{zhao2023parallel,
  title = {Parallelization Techniques for Convolutional Neural
  Networks on Embedded Systems},
  year = {2023},
  journal = {IEEE Transactions on Parallel and Distributed Systems},
  author = {Zhao, T. and Martin, R.},
  volume = {34},
  number = {4},
  pages = {1023--1038},
  doi = {10.1109/TPDS.2022.3231456},
  keywords = {parallelization, CNN, embedded systems, multi-core processing},
}

@article{park2022thread,
  title = {Thread Synchronization Mechanisms for Real-time Image Processing},
  year = {2022},
  journal = {Real-Time Systems Journal},
  author = {Park, K. and Lee, J.},
  volume = {58},
  number = {1},
  pages = {45--67},
  doi = {10.1007/s11241-021-09367-0},
  keywords = {thread synchronization, real-time systems, image processing},
}

@manual{amd2023vitis,
  title = {Vitis AI User Guide},
  year = {2023},
  author = {AMD},
  version = {v2.5},
  number = {UG1414},
  url = {https://docs.amd.com/r/en-US/ug1414-vitis-ai},
  keywords = {Vitis AI, deep learning, edge AI, FPGA acceleration},
}

@article{garcia2017review,
  title = {A Review on Deep Learning Techniques Applied to Semantic
  Segmentation},
  year = {2017},
  author = {Garcia-Garcia, A. and Orts-Escolano, S. and Oprea, S. and
  Villena-Martinez, V. and Garcia-Rodriguez, J.},
  journal = {ArXiv},
  volume = {1704.06857},
  url = {https://arxiv.org/abs/1704.06857},
  keywords = {semantic segmentation, deep learning, convolutional
  neural networks},
}

@book{beauchamp2007ethics,
  title = {Principles of Health Care Ethics},
  year = {2007},
  author = {Beauchamp, T. L.},
  edition = {2nd},
  publisher = {John Wiley \& Sons},
  address = {Oxford, UK},
  pages = {3--10},
  chapter = {The `Four Principles' Approach to Health Care Ethics},
  doi = {10.1002/9780470510544},
  keywords = {medical ethics, healthcare, four principles,
  beneficence, autonomy},
}

@article{elvinger2025gpu,
  title = {Measuring GPU utilization one level deeper},
  year = {2025},
  author = {Elvinger, S. and Li, Y. and Chen, X.},
  journal = {ArXiv},
  volume = {2501.16909},
  url = {https://arxiv.org/pdf/2501.16909},
  keywords = {GPU profiling, resource interference, kernel metrics,
  IPC, GPU utilization},
}

@misc{pytorch2023,
  title = {PyTorch: An Imperative Style, High-Performance Deep
  Learning Library},
  year = {2023},
  author = {Paszke, A. and Gross, S. and Massa, F. and Lerer, A. and
    Bradbury, J. and Chanan, G. and Killeen, T. and Lin, Z. and
    Gimelshein, N. and Antiga, L. and Desmaison, A. and Kopf, A. and
    Yang, E. and DeVito, Z. and Raison, M. and Tejani, A. and
  Chilamkurthy, S. and Steiner, B. and Fang, L. and Bai, J. and Chintala, S.},
  url = {https://pytorch.org},
  keywords = {deep learning, neural networks, GPU acceleration,
  machine learning framework},
}

@article{mlflow2023,
  title = {Accelerating the Machine Learning Lifecycle with MLflow},
  year = {2018},
  author = {Zaharia, Matei and Chen, Andrew and Davidson, Aaron and
    Ghodsi, Ali and Hong, Sue Ann and Konwinski, Andy and Murching,
    Siddharth and Nykodym, Tomas and Ogilvie, Paul and Parkhe, Mani and
    Sen, Avesh and Xie, Corey and Yan, Reynold and Wendell, Patrick and
  Stoica, Ion},
  journal = {IEEE Data Engineering Bulletin},
  volume = {41},
  number = {4},
  pages = {39--45},
  url = {http://sites.computer.org/debull/A18dec/p39.pdf},
  keywords = {machine learning, experiment tracking, model
  management, MLOps, reproducibility},
}

@techreport{ieee2802-2022,
  type = {Standard},
  key = {IEEE 2802-2022},
  month = {December},
  year = {2022},
  title = {{IEEE} Standard for Performance and Safety Evaluation of
  Artificial Intelligence Based Medical Device: Terminology},
  volume = {2802-2022},
  doi = {10.1109/IEEESTD.2022.10018145},
  institution = {IEEE},
  keywords = {artificial intelligence, medical devices, AI safety, terminology},
}

@techreport{ieee3129-2023,
  type = {Standard},
  key = {IEEE 3129-2023},
  month = {September},
  year = {2023},
  title = {{IEEE} Standard for Robustness Testing and Evaluation of
  Artificial Intelligence Based Image Recognition Service},
  volume = {3129-2023},
  doi = {10.1109/IEEESTD.2023.10273450},
  institution = {IEEE},
  keywords = {artificial intelligence, image recognition, robustness
  testing, AI evaluation},
}

@manual{amd_ug1354_kv260,
  title        = {KV260 Vision AI Starter Kit},
  subtitle     = {Vitis AI Library User Guide (UG1354), Version 2.5},
  author       = {{AMD Xilinx}},
  organization = {Advanced Micro Devices, Inc.},
  year         = {2022},
  note         = {Section ``KV260 Vision AI Starter Kit'' describes
    that one B4096 DPU core in PL delivers 1.23~TOPS INT8 peak
  performance and provides throughput at 300\,MHz for various models},
  url          =
  {https://docs.amd.com/r/2.5-English/ug1354-xilinx-ai-sdk/KV260-Vision-AI-Starter-Kit}
}

@online{amd_kv260_b4096_forum,
  author  = {{AMD Support Community}},
  title   = {With Kria KV260, how many cores in DPU and how many DPUs
  we can integrate in KV260 at most?},
  year    = {2024},
  note    = {AMD engineer notes that the maximum size of DPU
  implemented for K26 SoMs or KV260 is B4096 at 300\,MHz, single core},
  url     =
  {https://adaptivesupport.amd.com/s/question/0D54U000088eNqJSAU/with-kria-kv260-how-many-cores-in-dpu-and-how-many-dpus-we-can-integrate-in-kv260-at-most?language=en_US},
  urldate = {2025-11-13}
}

@manual{xilinx2022petalinux,
  title        = {PetaLinux Tools Documentation: Reference Guide},
  author       = {{AMD Xilinx}},
  organization = {Advanced Micro Devices, Inc.},
  year         = {2022},
  version      = {2022.2},
  number       = {UG1144},
  url          =
  {https://docs.amd.com/r/en-US/ug1144-petalinux-tools-reference-guide},
  keywords     = {PetaLinux, embedded Linux, Zynq UltraScale+, device
  drivers, kernel configuration}
}

@article{lakshminarayanan2023health,
  title={Health Care Equity Through Intelligent Edge Computing and
  Augmented Reality/Virtual Reality: A Systematic Review},
  author={Lakshminarayanan, Vishal and Ravikumar, Aswathy and
  Sriraman, Harini and Alla, Sujatha and Chattu, Vijay Kumar},
  journal={Journal of Multidisciplinary Healthcare},
  volume={16},
  pages={2839--2859},
  year={2023},
  publisher={Dove Press},
  doi={10.2147/JMDH.S419923},
  pmcid={PMC10519219}
}

@techreport{provost2022eye,
  title = {Eye Tracking for Seizure Detection},
  author = {Provost, Brian and Vonderheide, David},
  year = {2022},
  institution = {Dartmouth College},
  type = {ENGS 89/90 Reports},
  number = {57},
  url = {https://digitalcommons.dartmouth.edu/engs89_90/57},
  keywords = {eye tracking, seizure detection, medical monitoring,
  head motion, IMU sensors},
}

@article{sedighsarvestani2012eyelid,
  title = {Abnormal Eyelid Dynamics in Absence Seizures},
  author = {Sedigh-Sarvestani, Madineh and Saunders, Aman and
  Touhami, Anas and Gluckman, Bruce J.},
  journal = {PLOS ONE},
  year = {2012},
  volume = {7},
  number = {11},
  pages = {e50845},
  doi = {10.1371/journal.pone.0050845},
  keywords = {absence seizures, eyelid dynamics, seizure detection,
  neurological indicators, epilepsy},
}

@incollection{evinger2011blinking,
  title = {Blinking and Eye Movements: Physiological Mechanisms and
  Clinical Implications},
  author = {Evinger, Craig and Bao, Jennifer B. and Powers, Andrea S.
  and Kassem, Ihab S.},
  booktitle = {Progress in Brain Research},
  volume = {192},
  year = {2011},
  pages = {167--187},
  publisher = {Elsevier},
  doi = {10.1016/B978-0-444-53355-5.00011-9},
  keywords = {blink reflex, eye movements, neurophysiology, clinical
  neurology, motor control},
}

@article{stefan2007eyelid,
  title = {Eyelid Myoclonia as a Distinct Seizure Presentation in
  Idiopathic Generalized Epilepsy},
  author = {Stefan, Hermann and Rampp, Stefan and Hopfeng{\"a}rtner,
  R{\"u}diger},
  journal = {Epilepsy Research},
  year = {2007},
  volume = {73},
  number = {1},
  pages = {18--23},
  doi = {10.1016/j.eplepsyres.2006.07.014},
  keywords = {eyelid myoclonia, seizure semiology, idiopathic
  generalized epilepsy, ictal signs},
}

@misc{onnxruntime,
  title={ONNX Runtime},
  author={ONNX Runtime developers},
  year={2021},
  howpublished={\url{https://onnxruntime.ai/}},
  note={Version: 1.19.0}
}

@misc{netron,
  title={Netron: Visualizer for Neural Network, Deep Learning, and
  Machine Learning Models},
  author={Roeder, Lutz},
  year={2024},
  howpublished={\url{https://github.com/lutzroeder/netron}},
  note={Open-source neural network model visualizer supporting ONNX,
  TensorFlow, PyTorch, and other formats}
}

@misc{modal2024,
  title={Modal: Serverless GPU Compute for Machine Learning},
  author={{Modal Labs}},
  year={2024},
  howpublished={\url{https://modal.com}},
  note={Cloud platform for scalable GPU workloads with containerized
  environments}
}

@inproceedings{kervadec2019boundary,
  title={Boundary Loss for Highly Unbalanced Segmentation},
  author={Kervadec, Hoel and Bouchtiba, Jihene and Desrosiers,
  Christian and Granger, Eric and Dolz, Jose and Ayed, Ismail Ben},
  booktitle={International Conference on Medical Imaging with Deep
  Learning (MIDL)},
  pages={285--296},
  year={2019},
  url={https://arxiv.org/abs/1812.07032},
  keywords={boundary loss, surface loss, semantic segmentation, class
  imbalance, distance transform}
}

@misc{onnx2023,
  title={ONNX: Open Neural Network Exchange},
  author={{ONNX Community}},
  year={2023},
  howpublished={\url{https://onnx.ai/}},
  note={Open standard for machine learning model representation and
  interoperability}
}

@misc{onnx_extract_model,
  title={ONNX Utils: extract\_model},
  author={{ONNX Community}},
  year={2023},
  howpublished={\url{https://onnx.ai/onnx/\_modules/onnx/utils.html\#Extractor}},
  note={Function for extracting sub-models from ONNX models by
  specifying input and output tensor names}
}

@inproceedings{li2021condseg,
  title={CondSeg: Ellipse Estimation of Pupil and Iris via Conditioned Segmentation},
  author={Li, Zhengyu and Demiris, Yiannis},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2045--2051},
  year={2021},
  organization={IEEE},
  doi={10.1109/ICRA48506.2021.9389650},
  keywords={pupil detection, iris segmentation, conditioned segmentation, ellipse estimation, eye tracking, gaze estimation}
}

@article{fuhl2024ellseg,
  title={EllSeg: An Ellipse Segmentation Framework for Robust Gaze Tracking},
  author={Fuhl, Wolfgang and Bozkir, Efe and Brosch, Tobias and Castner, Niklas and Geisler, Daniel and Pereira, Thiago Santini and Tonsen, Marc and Kasneci, Enkelejda},
  journal={arXiv preprint arXiv:2408.17231},
  year={2024},
  url={https://arxiv.org/abs/2408.17231},
  keywords={gaze tracking, ellipse segmentation, eye tracking, pupil detection, robust segmentation, real-time processing}
}

@inproceedings{cai2022efficientvit,
  title={EfficientViT: Multi-Scale Linear Attention for High-Resolution Dense Prediction},
  author={Cai, Han and Li, Junyan and Hu, Muyan and Gan, Chuang and Han, Song},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2022},
  url={https://arxiv.org/abs/2205.14756},
  keywords={vision transformer, linear attention, semantic segmentation, dense prediction, efficient models, high-resolution}
}

@article{tang2025nativesparseattention,
  title={Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention},
  author={Tang, Yicheng and Wang, Yuxin and Chen, Jiaxiang and Zhou, Haoyu and Li, Haoran and Zhang, Zhengyang and Lin, Ji},
  journal={arXiv preprint arXiv:2502.11089},
  year={2025},
  url={https://arxiv.org/abs/2502.11089},
  keywords={sparse attention, hardware efficiency, transformer optimization, attention mechanism, edge computing}
}
