\chapter{Introduction}\label{chap:introduction}

\section{Problem Statement}\label{sec:problem-statement}

Individuals with mobility impairments and underlying medical conditions face critical challenges detecting and responding to medical episodes that can occur unexpectedly, posing significant risks to their safety and independence. Current assistive technologies are reactive, requiring human intervention after an episode occurs, leading to delayed response times and potential complications.

Advancements in AI and edge computing enable real-time health monitoring~\cite{chen2021edge,smith2023eyetracking}, yet remain underutilized in assistive mobility devices. Our project leverages semantic segmentation at the edge to analyze eye movement and body posture, detecting early warning signs of medical distress to autonomously reposition wheelchair users to safer positions. Using established U-Net architectures~\cite{ronneberger2015}, this approach provides proactive real-time monitoring that enhances safety while preserving user independence.

\section{Intended Users}\label{sec:intended-users}

This system serves three user groups: (1) wheelchair users with mobility impairments and conditions such as cerebral palsy, epilepsy, or cardiovascular disorders who require autonomous medical episode detection; (2) caregivers and family members who need real-time health alerts without constant supervision; and (3) healthcare providers and emergency responders who rely on accurate physiological data for rapid medical decision-making~\cite{beauchamp2007ethics}.
