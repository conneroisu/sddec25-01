\chapter{Implementation}\label{chap:implementation}

\section{Current Implementation Status}\label{sec:current-status}

Our project has completed comprehensive performance evaluation of both single-model and split-model architectures on the AMD Kria KV260 development board. The implementation follows a structured approach focusing on the critical path items while maintaining flexibility for iterative improvements.

\subsection{Development Environment Setup}\label{subsec:development-environment}

\begin{itemize}
\item \textbf{Hardware Configuration}: AMD Kria KV260 development board fully configured with necessary peripherals
\item \textbf{Software Stack}: Vitis-AI development environment~\cite{amd2023vitis} installed and operational
\item \textbf{Version Control}: Git repository established with comprehensive documentation
\item \textbf{Build System}: Docker-based development environment for consistency across team members
\end{itemize}

\subsection{Performance Results}\label{subsec:performance-results}

We have conducted extensive benchmarking of both single-model and split-model implementations to evaluate the trade-offs between different parallelization strategies.

\subsubsection{Single Model Performance}\label{subsubsec:single-model-performance}

The baseline U-Net implementation running as a single unified model demonstrates the following performance characteristics:

\begin{itemize}
\item \textbf{Mean Total Latency}: 529.39 ms ($\pm$ 0.26 ms)
\item \textbf{Mean DPU Time}: 474.32 ms ($\pm$ 0.05 ms)
\item \textbf{Mean Preprocess}: 27.43 ms ($\pm$ 0.23 ms)
\item \textbf{Mean Postprocess}: 27.64 ms ($\pm$ 0.08 ms)
\item \textbf{Memory Usage}: 45.00 MB
\end{itemize}

The single model implementation provides a stable baseline with low variance in processing times, indicating consistent performance across frames. The dominant processing time is spent in DPU execution (89.6\% of total latency), with preprocessing and postprocessing contributing approximately 10\% of overall latency.

\subsubsection{Split Model Performance (4 Segments)}\label{subsubsec:split-model-performance}

The parallelized implementation dividing the U-Net algorithm into four segments demonstrates the following characteristics:

\begin{itemize}
\item \textbf{Mean Total Latency}: 784.29 ms ($\pm$ 3.39 ms)
\item \textbf{Mean DPU Time}: 729.00 ms ($\pm$ 3.38 ms)
\item \textbf{Mean Preprocess}: 27.64 ms ($\pm$ 0.18 ms)
\item \textbf{Mean Postprocess}: 27.64 ms ($\pm$ 0.01 ms)
\end{itemize}

The split model approach incurs additional overhead from thread coordination and data transfer between segments, resulting in 48.2\% higher total latency compared to the single model. The increased variance ($\pm$ 3.39 ms vs. $\pm$ 0.26 ms) indicates synchronization overhead and resource contention between parallel threads.

\subsection{Performance Analysis}\label{subsec:performance-analysis}

\begin{itemize}
\item \textbf{Parallelization Overhead}: The split model demonstrates that naive algorithm division introduces significant overhead (255 ms increase) due to thread synchronization and inter-segment data transfer
\item \textbf{Memory Efficiency}: Single model maintains a lower memory footprint (45 MB) when compared to split model inference (111.01 MB). This increase in memory footprint is caused by the intermediate storage of tensors needed as inputs for further UNet segments.
\end{itemize}

\subsection{Algorithm Analysis and Division}\label{subsec:algorithm-analysis}

The U-Net semantic segmentation algorithm has been thoroughly analyzed for pipelined processing optimization~\cite{zhao2023parallel}:

\begin{itemize}
\item \textbf{Architecture Review}: Complete understanding of encoder-decoder structure and skip connections
\item \textbf{Pipeline Strategy}: Architectural approach developed for efficient pipelined processing with overlapped CPU and DPU stages
\item \textbf{Accuracy Validation}: Current implementation achieves 98.8\% IoU accuracy, within target range of 99.8\%~\cite{wang2021}
\item \textbf{Performance Baseline}: Comprehensive benchmarking completed for both single and split model architectures
\end{itemize}

\subsection{Resource Scheduling Implementation}\label{subsec:scheduling-implementation}

\begin{itemize}
\item \textbf{DPU Access Management}: Sequential scheduling system (round-robin) designed for fair DPU access allocation
\item \textbf{Thread Coordination}: Multi-threading framework implemented for CPU-based preprocessing and postprocessing~\cite{park2022thread}
\item \textbf{Memory Management}: Optimized memory allocation strategy for efficient pipelined data flow~\cite{chen2022memory}
\item \textbf{Synchronization}: Inter-thread communication mechanisms established for pipeline stage coordination
\end{itemize}

\section{Model Training}\label{sec:model-training}

\subsection{Training Infrastructure}\label{subsec:training-infrastructure}

The U-Net semantic segmentation model training process underwent significant optimization to improve both training efficiency and model performance. Our enhanced training infrastructure leverages GPU acceleration through PyTorch~\cite{pytorch2023} with carefully designed batched operations and optimized data flow patterns.

\subsection{GPU-Optimized Training Pipeline}\label{subsec:gpu-optimized-training}

The training implementation prioritizes GPU-native operations to minimize the performance overhead traditionally associated with CPU-GPU data transfers. Key optimizations include:

\begin{itemize}
\item \textbf{Batched Operations}: All training operations utilize batched GPU kernels, eliminating the need for sequential per-sample processing
\item \textbf{In-GPU Metrics Calculation}: Performance metrics (IoU, loss, accuracy) are computed directly within GPU kernels rather than transferring data to CPU for calculation~\cite{elvinger2025gpu}
\item \textbf{Minimized CPU-GPU Transfers}: Data pipeline designed to keep tensors on GPU throughout forward pass, backward pass, and metric computation
\item \textbf{Optimized Memory Management}: Careful buffer allocation to prevent unnecessary memory copies between device and host
\end{itemize}

\subsection{Training Performance Improvements}\label{subsec:training-performance}

The optimized PyTorch training script achieved remarkable performance improvements over the previous training implementation:

\begin{itemize}
\item \textbf{Training Time Reduction}: Complete model training reduced from approximately 12 hours to 50 minutes, representing a 15x speedup
\item \textbf{Model Performance}: Achieved 0.01 increase in IoU accuracy (from 98.8\% to 98.9\%)
\item \textbf{Resource Utilization}: Improved GPU utilization through elimination of idle time during CPU-GPU synchronization
\item \textbf{Convergence Stability}: Batched operations provide more stable gradient estimates, leading to faster convergence
\end{itemize}

The dramatic speedup is primarily attributed to eliminating excessive CPU-GPU round trips that characterized the previous training approach. By maintaining all computation within GPU kernels and computing metrics device-side, the training pipeline achieves near-optimal GPU utilization.

\subsection{Experiment Tracking and Artifact Management}\label{subsec:experiment-tracking}

Training experiments are tracked using MLflow~\cite{mlflow2023}, providing comprehensive logging of training artifacts and performance metrics:

\begin{itemize}
\item \textbf{Hyperparameter Logging}: Automatic tracking of learning rate, batch size, optimizer configuration, and model architecture parameters
\item \textbf{Training Metrics}: Real-time logging of loss curves, IoU scores, and accuracy metrics across training epochs
\item \textbf{Model Artifacts}: Versioned storage of trained model weights, optimizer states, and training checkpoints
\item \textbf{Performance Profiling}: Recording of GPU memory usage, training throughput, and computational efficiency metrics
\item \textbf{Reproducibility}: Complete environment and dependency tracking for reproducible training runs
\end{itemize}

\subsection{GPU Metrics Methodology}\label{subsec:gpu-metrics-methodology}

Following best practices for GPU performance measurement~\cite{elvinger2025gpu}, our training implementation computes all performance metrics directly within GPU kernels rather than relying on CPU-side calculations. This approach provides several advantages:

\begin{itemize}
\item \textbf{Fine-Grained Profiling}: Access to device-level performance counters including instruction throughput (IPC), streaming multiprocessor (SM) utilization, and memory bandwidth usage
\item \textbf{Reduced Synchronization Overhead}: Eliminating host-device synchronization points that would otherwise stall the GPU pipeline
\item \textbf{Accurate Resource Measurement}: Direct measurement of kernel-level resource interference and L1/L2 cache utilization
\item \textbf{Real-Time Monitoring}: Continuous performance tracking without impacting training throughput
\end{itemize}

The methodology aligns with recent research demonstrating that conventional ``GPU utilization'' metrics measured from the CPU side are insufficient for understanding true GPU resource usage~\cite{elvinger2025gpu}. By measuring performance at the kernel level using device-side counters, we achieve more accurate characterization of computational efficiency and identify optimization opportunities that would be invisible to host-side profiling tools.

\subsection{Training Dataset and Validation}\label{subsec:training-dataset}

The model training process utilizes a comprehensive eye-tracking dataset with careful attention to data quality and validation:

\begin{itemize}
\item \textbf{Dataset Split}: 80\% training, 20\% validation following standard practices
\item \textbf{Data Augmentation}: Real-time augmentation on GPU including rotation, scaling, and brightness variations
\item \textbf{Quality Validation}: Automated verification of annotation quality and dataset consistency
\item \textbf{Cross-Validation}: Multiple training runs with different random seeds to ensure model robustness
\end{itemize}

\section{Implementation Challenges}\label{subsec:implementation-challenges}

\subsection{Technical Challenges}\label{subsec:technical-challenges}

\begin{itemize}
\item \textbf{Memory Constraints}: Working within 4GB DDR memory limitations while supporting pipelined processing across multiple algorithms
\item \textbf{Thread Synchronization}: Ensuring proper coordination between pipeline processing threads without deadlocks or race conditions
\item \textbf{Sequential DPU Scheduling}: Efficiently scheduling the single DPU to balance semantic segmentation requirements with periodic data collection needs of auxiliary algorithms
\item \textbf{Performance Optimization}: Achieving target pipelined throughput for real-time operation
\end{itemize}

\section{Future Implementation Plans}\label{subsec:future-implementation}

\subsection{Short-term Goals (Next 4 weeks)}\label{subsec:short-term-goals}

\begin{itemize}
\item Complete implementation of pipelined U-Net processing
\item Optimize DPU scheduling system for maximum throughput
\item Implement comprehensive testing framework
\item Validate accuracy maintenance across pipelined implementation
\end{itemize}

\subsection{Medium-term Goals (Next 8 weeks)}\label{subsec:medium-term-goals}

\begin{itemize}
\item Achieve target pipelined performance for real-time operation
\item Complete integration testing with all auxiliary algorithms and DPU scheduling
\item Optimize memory usage and buffer management for pipelined data flow
\item Implement robust error handling and recovery mechanisms
\end{itemize}

\subsection{Long-term Goals (Next 12 weeks)}\label{subsec:long-term-goals}

\begin{itemize}
\item Full system validation against all requirements
\item Performance optimization and fine-tuning
\item Documentation and preparation for deployment
\item User acceptance testing and feedback incorporation
\end{itemize}

\section{Implementation Methodology}\label{subsec:implementation-methodology}

\subsection{Agile Development Approach}\label{subsec:agile-approach}

Our implementation follows an agile methodology with:

\begin{itemize}
\item \textbf{Sprint Planning}: 2-week sprints with specific deliverables
\item \textbf{Daily Standups}: Progress tracking and issue identification
\item \textbf{Sprint Reviews}: Demonstration of completed features
\item \textbf{Retrospectives}: Process improvement and adaptation
\end{itemize}

\subsection{Version Control and Documentation}\label{subsec:version-control}

\begin{itemize}
\item \textbf{Git Workflow}: Feature branch development with code review process
\item \textbf{Documentation}: Comprehensive documentation of implementation decisions and progress
\item \textbf{Testing Integration}: Automated testing integrated into development workflow
\item \textbf{Client Communication}: Regular updates and demonstrations for stakeholder alignment
\end{itemize}

\section{Tools and Technologies}\label{subsec:tools-technologies}

\subsection{Development Tools}\label{subsec:development-tools}

\begin{itemize}
\item \textbf{Xilinx Vitis-AI}~\cite{amd2023vitis}: Primary development environment for AI acceleration
\item \textbf{Docker}: Containerized development environment for consistency
\item \textbf{GCC/G++}: C++ development with optimization flags for performance
\item \textbf{Git}: Version control and collaboration platform
\end{itemize}

\subsection{Testing and Debugging Tools}\label{subsec:testing-tools}

\begin{itemize}
\item \textbf{Vitis AI Profiler}: Performance analysis and bottleneck identification
\item \textbf{Custom Logging Framework}: Real-time system monitoring and debugging
\item \textbf{Automated Testing Suite}: Comprehensive validation framework
\item \textbf{Hardware Monitoring Tools}: Resource utilization tracking
\end{itemize}

\section{Performance Metrics and Monitoring}\label{subsec:performance-monitoring}

\subsection{Key Performance Indicators}\label{subsec:kpis}

\begin{itemize}
\item \textbf{Processing Throughput}: Frames per second (target: >60 FPS)
\item \textbf{Accuracy}: Intersection over Union (target: 99.8\%)
\item \textbf{Latency}: End-to-end processing time (target: <16.6ms per frame)
\item \textbf{Resource Utilization}: CPU, memory, and DPU usage efficiency
\end{itemize}

\subsection{Monitoring Implementation}\label{subsec:monitoring-implementation}

\begin{itemize}
\item \textbf{Real-time Metrics}: Live performance monitoring during operation
\item \textbf{Historical Tracking}: Performance trend analysis over time
\item \textbf{Alert System}: Automatic notification of performance degradation
\item \textbf{Reporting}: Comprehensive performance analysis reports
\end{itemize}

\section{Code Architecture}\label{subsec:code-architecture}

\subsection{Modular Design}\label{subsec:modular-design}

\begin{itemize}
\item \textbf{Separation of Concerns}: Clear boundaries between algorithm components
\item \textbf{Interface Design}: Well-defined APIs between system components
\item \textbf{Error Handling}: Comprehensive error management and recovery
\item \textbf{Scalability}: Architecture designed for future enhancements
\end{itemize}

\subsection{Thread Management}\label{subsec:thread-management}

\begin{itemize}
\item \textbf{Thread Pool}: Efficient thread creation and management
\item \textbf{Synchronization}: Mutexes, semaphores, and condition variables for coordination~\cite{park2022thread}
\item \textbf{Load Balancing}: Dynamic workload distribution across available cores
\item \textbf{Deadlock Prevention}: Strategies to avoid thread deadlock scenarios
\end{itemize}
