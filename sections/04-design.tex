\chapter{Design}\label{chap:design}

\section{Design Context}\label{sec:design-context}

\subsection{Broader Context}\label{subsec:broader-context}

This project addresses the needs of individuals with mobility impairments who require eye-tracking systems for communication and assistive device control, particularly those with conditions such as cerebral palsy depending on efficient eye tracking for daily activities and medical monitoring.

\begin{table}[htbp]
\centering
\renewcommand{\arraystretch}{1.2}
\caption{Design Context Analysis}
\begin{tabular}{p{2.5cm}p{4.5cm}p{5.5cm}}
\toprule
\textbf{Area} & \textbf{Description} & \textbf{Examples} \\
\midrule
Public health, safety, and welfare &
Our project directly improves the safety and well-being of individuals with mobility impairments by enhancing the responsiveness of eye-tracking medical monitoring systems. &
Faster response times to potential medical issues, more reliable detection of eye movements for wheelchair control, reduced risk of incidents for users \\
\midrule
Global, cultural, and social &
The solution respects the values of independence and dignity for people with disabilities while acknowledging the cultural practices around care and assistance. &
Supports the right to autonomy for people with disabilities, aligns with medical ethics of beneficence~\cite{beauchamp2007ethics}, works within existing healthcare frameworks \\
\midrule
Ecological &
By optimizing software rather than requiring new hardware, our solution extends the useful life of existing devices and reduces electronic waste. &
Reduced need for frequent hardware replacement, lower energy consumption through optimized processing \\
\midrule
Economic &
Our optimization approach provides significant performance improvements while keeping costs accessible for healthcare providers and individuals. &
Affordable enhancement to existing assistive technology systems, more efficient use of available computing resources, potential reduction in healthcare costs through preventative monitoring \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Prior Work and Solutions}\label{subsec:prior-work}

Several approaches have been used to implement semantic segmentation for eye tracking~\cite{garcia2017review}, but most face limitations when deployed on resource-constrained edge devices:

\begin{enumerate}
\item \textbf{Wang et al. (2021)}~\cite{wang2021} proposed ``EfficientEye: A Lightweight Semantic Segmentation Framework for Eye Tracking'', which achieved good accuracy but still required substantial computational resources. Their approach reduced model size but processing speed remained at approximately 120 ms per frame.

\item \textbf{Previous Project Iteration} implemented a standard U-Net architecture on the Kria KV260 board with high accuracy (99.8\% IoU) but could only process a single frame every 160ms, which is insufficient for real-time application needs.

\item \textbf{Commercial Solutions} like Tobii Pro Fusion offer high-speed eye tracking (250 Hz) but require dedicated hardware and specialized processors, making them expensive and difficult to integrate into existing assistive devices.
\end{enumerate}

\subsubsection{Advantages of Our Approach}
\begin{itemize}
\item Maintains high accuracy while significantly improving processing speed
\item Utilizes existing hardware (Kria KV260) without requiring costly upgrades
\item Implements a pipelined approach that maximizes system throughput through overlapped CPU and DPU processing
\item Integrates with existing assistive wheelchair technology ecosystem
\end{itemize}

\subsubsection{Limitations of Our Approach}
\begin{itemize}
\item Requires careful optimization of memory and DPU resources
\item Complexity in thread synchronization and pipeline management
\item Dependent on specific hardware architecture (Kria KV260)
\end{itemize}

\subsection{Technical Complexity}\label{subsec:technical-complexity}

Our project demonstrates significant technical complexity in both its components and requirements:

\begin{enumerate}
\item \textbf{Multiple Components with Distinct Scientific Principles:}
   \begin{itemize}
   \item \textbf{Neural Network Architecture:} The U-Net semantic segmentation algorithm incorporates complex convolutional neural network principles with encoder-decoder architecture~\cite{burden2013}
   \item \textbf{Pipelined Computing:} Implementation of multi-threaded CPU processing and pipeline architecture leverages computer architecture principles~\cite{zhao2023parallel}
   \item \textbf{Memory Management:} Developing efficient memory allocation strategies based on computer systems principles
   \item \textbf{Real-time Systems:} Balancing processing load to meet strict timing constraints based on real-time systems theory
   \item \textbf{Resource Scheduling:} Creating optimal sequential DPU scheduling mechanisms based on operating systems principles, managing the constraint that the DPU can only execute one xmodel inference at a time
   \end{itemize}

\item \textbf{Challenging Requirements:}
   \begin{itemize}
   \item \textbf{Speed Improvement:} Achieving near 5x throughput improvement through pipelining exceeds typical optimization gains in the industry
   \item \textbf{Accuracy Maintenance:} Preserving high accuracy while implementing complex pipelined processing is significantly more challenging than standard optimization
   \item \textbf{Resource Constraints:} Working within the limited memory (4GB) and single-DPU architecture of the Kria board requires innovative scheduling solutions
   \item \textbf{Real-time Performance:} Meeting the 60 frames per second requirement is at the upper end of what is possible with current embedded AI systems
   \end{itemize}
\end{enumerate}

The combination of these elements, particularly maintaining accuracy while implementing efficient pipelined execution with resource scheduling across multiple algorithms, represents technical complexity beyond standard engineering solutions.

\section{Design Exploration}\label{sec:design-exploration}

\subsection{Design Decisions}\label{subsec:design-decisions}

We have identified the following key design decisions that are critical to the success of our Semantic Segmentation Optimization project:

\begin{enumerate}
\item \textbf{Sequential DPU Scheduling}
   \begin{itemize}
   \item \textbf{Decision:} Implement round-robin or priority-based scheduling for the single DPU, coordinating access among semantic segmentation, blink detection, and eye tracking algorithms while preventing resource starvation.
   \item \textbf{Importance:} Fair scheduling ensures all algorithms meet periodic data collection requirements (critical for maintaining accuracy) while achieving target throughput and 99.8\% IoU accuracy.
   \end{itemize}

\item \textbf{Single DPU Architecture Constraint}
   \begin{itemize}
   \item \textbf{Decision:} Utilize the single B4096 DPU core (300MHz) on the KV260 board rather than exploring dual smaller DPU configurations.
   \item \textbf{Rationale:} The KV260's FPGA fabric technically supports implementing two smaller DPUs (B1024 or B512) instead of the single large B4096 core. Both our team and a previous ISU team concluded that dual smaller DPUs would be advantageous, especially given our reduced semantic segmentation requirements. However, our client directed us to maintain the existing single B4096 DPU architecture and not explore the dual DPU approach.
   \item \textbf{Importance:} This client-driven constraint significantly impacts our optimization strategy. The single DPU architecture prevents us from leveraging hardware-level parallelism. Instead, we must focus on efficient time-division scheduling and resource sharing mechanisms to achieve our performance goals. This architecture necessitates careful coordination of algorithm access patterns and optimized scheduling to prevent resource contention while meeting our throughput targets.
   \end{itemize}
\end{enumerate}

\subsection{Ideation}\label{subsec:ideation}

For our resource scheduling approach, we explored several potential scheduling strategies through a structured ideation process:

\begin{enumerate}
\item \textbf{Round-Robin Scheduling}
   \begin{itemize}
   \item Allocate DPU time in equal slices to each algorithm in circular order
   \item Simple to implement and ensures each algorithm gets fair access
   \item May not be optimal for variable processing requirements
   \end{itemize}

\item \textbf{Priority-Based Scheduling}
   \begin{itemize}
   \item Assign priority levels to algorithms based on urgency of data collection needs
   \item Higher priority tasks preempt lower priority ones when necessary
   \item Could be tuned to ensure periodic data collection requirements are met
   \end{itemize}

\item \textbf{Time-Division Multiplexing}
   \begin{itemize}
   \item Allocate specific time windows for each algorithm to access the DPU
   \item Synchronize windows with periodic data collection requirements
   \item Optimizes for predictable execution patterns
   \end{itemize}
\end{enumerate}

These options were generated through team brainstorming sessions, a literature review of resource scheduling techniques, and an analysis of the periodic data requirements of the algorithms.

\subsection{Decision-Making and Trade-Offs}\label{subsec:decision-making}

The client required maintaining baseline accuracy due to the medical nature of the application. Our scheduling approach balances performance improvements with fair resource allocation, ensuring all algorithms meet periodic data collection requirements to prevent data corruption. The system minimizes memory transfer overhead while accommodating OS tasks and additional ML algorithms through appropriate DPU time slice allocation.

\section{Proposed Design}\label{sec:proposed-design}

\subsection{Overview}\label{subsec:overview}

This project optimizes a U-Net-based eye tracking system that monitors eye movements to detect medical issues and automatically reposition wheelchair users. The pipelined architecture leverages multi-threaded CPU processing with sequential DPU execution to achieve approximately 8.3ms per frame (33.2ms for 4 frames), improving speed nearly 5x from the baseline 160ms per frame. The system captures images, processes them via pipelined semantic segmentation, tracks eye position and blinks, then interfaces with wheelchair control systems. The key innovation is efficient sequential DPU scheduling on the AMD Kria KV260's single-DPU, limited-memory architecture.

\subsection{Detailed Design}\label{subsec:detailed-design}

Our semantic segmentation optimization system consists of the following key components:

\subsubsection{Hardware Platform}
\begin{itemize}
\item \textbf{AMD Kria KV260 Development Board}~\cite{xilinx2022kv260}
  \begin{itemize}
  \item System-on-Module (SoM) with programmable logic
  \item Quad-core ARM processor
  \item Deep Processing Unit (DPU) for accelerating neural network inference
  \item Four 1GB DDR4 memory banks
  \item Various I/O interfaces for camera input and system communication
  \end{itemize}
\end{itemize}

\subsubsection{Software Components}
\begin{enumerate}
\item \textbf{U-Net Semantic Segmentation}: Processes eye images for pixel-level pupil segmentation
\item \textbf{Preprocessing Module}: Handles image normalization, scaling, and filtering before U-Net processing
\item \textbf{Blink Detection}: Lightweight neural network detecting eye closure states
\item \textbf{Thread Management System}~\cite{park2022thread}: Coordinates execution, synchronization, and resource allocation across pipeline stages
\end{enumerate}

\subsubsection{Processing Pipeline}
The system implements four stages~\cite{zhao2023parallel}: (1) image capture and preprocessing with normalization/filtering, (2) pipelined semantic segmentation with overlapped CPU/DPU processing and coordinated scheduling, (3) feature extraction for pupil tracking and blink detection, and (4) output generation for medical distress detection and wheelchair control.

\subsubsection{Memory Allocation Strategy}
Distributed memory usage across four DDR4 banks~\cite{chen2022memory}, circular buffers for data flow, cache optimization to minimize transfers, and thread-local storage for each processing thread.

\subsection{Functionality}\label{subsec:functionality}

The system performs: initialization (hardware configuration, model loading, thread setup, memory allocation), normal operation (continuous capture, pipelined processing, real-time tracking), error response (detection/recovery, graceful degradation, alerts, emergency protocols), and user control (manual override, adjustable parameters, status monitoring, configuration interface).

\subsection{Areas of Concern and Development}\label{subsec:areas-concern}

Key development focuses: performance optimization, efficient DPU scheduling, thread synchronization, memory efficiency, error handling, and real-time constraint compliance.

\section{Technology Considerations}\label{sec:technology-considerations}

\subsection{Kria Board KV260}
The AMD Kria KV260 provides an excellent balance of performance and power efficiency for our application:

\begin{itemize}
\item \textbf{Processing Power:} Quad-core ARM Cortex-A53 with 1.5 GHz clock speed
\item \textbf{AI Acceleration:} Integrated Deep Learning Processing Unit (DPU) for neural network inference
\item \textbf{Memory System:} 4GB DDR4 memory with four banks for parallel access
\item \textbf{Connectivity:} Multiple I/O interfaces for camera integration and system communication
\item \textbf{Power Efficiency:} Low power consumption suitable for mobile applications
\end{itemize}

\subsubsection{DPU Architecture Options}
The KV260's FPGA fabric offers flexibility in DPU configuration. The maximum single-core DPU configuration for K26 SoM and KV260 is the B4096 architecture (feature customized at 300MHz)~\cite{amd_ug1354_kv260,amd_kv260_b4096_forum}. However, the FPGA fabric technically supports alternative configurations:

\begin{itemize}
\item \textbf{Single Large Core:} B4096 DPU at 300MHz (current implementation)
\item \textbf{Dual Smaller Cores:} Two B1024 or B512 DPUs enabling true multi-core parallel processing
\end{itemize}

While dual smaller DPUs could provide benefits for our workload—particularly with reduced semantic segmentation requirements and multiple concurrent algorithms—our client specified maintaining the single B4096 configuration. This architectural constraint was established based on the existing system design and integration considerations, necessitating our focus on software-level optimization and efficient resource scheduling rather than hardware-level parallelism.

\subsection{U-Net Semantic Segmentation Algorithm}
The U-Net architecture~\cite{ronneberger2015} provides encoder-decoder structure with skip connections that preserve spatial information crucial for pupil detection, while demonstrating the required accuracy and offering modular design for pipelined processing.

\subsection{Vitis-AI and Vitas-Runtime}
The Xilinx Vitis-AI development ecosystem~\cite{amd2023vitis} provides essential tools for our optimization:

\begin{itemize}
\item \textbf{Model Optimization:} Quantization and pruning capabilities for performance improvement
\item \textbf{DPU Integration:} Seamless interface with hardware acceleration resources
\item \textbf{Performance Profiling:} Detailed analysis tools for bottleneck identification
\item \textbf{Memory Management:} Efficient buffer allocation and transfer optimization
\end{itemize}

\subsection{Alternative Technologies Considered}
During our design process, we evaluated several alternative approaches:

\begin{itemize}
\item \textbf{Cloud-Based Processing:} Rejected due to latency and connectivity requirements
\item \textbf{Hardware Upgrades:} Considered but would increase system cost and complexity
\item \textbf{Model Simplification:} Would compromise accuracy below medical requirements
\item \textbf{Alternative Neural Networks:} U-Net provides optimal balance of accuracy and performance
\end{itemize}

\section{Design Analysis}\label{sec:design-analysis}

\subsection{Current Implementation Status:}
Our comprehensive benchmarking has evaluated both single-model and split-model implementations. The single model achieves 529.39 ms total latency with 98.8\% IoU accuracy. The split model (4 segments) demonstrates 784.29 ms latency, revealing that naive parallelization introduces significant overhead (48.2\% increase) due to thread synchronization and inter-segment data transfer. These results inform future optimization strategies focusing on pipeline parallelism and efficient resource scheduling rather than simple algorithm division.

\subsection{Implementation Challenges:}
\begin{itemize}
\item Single DPU constraint requiring scheduling among multiple algorithms
\item Memory bandwidth constraints affecting data flow between processing stages
\item Thread synchronization overhead in pipelined processing
\item Balancing DPU access time allocation between multiple algorithms
\end{itemize}

\subsection{Future Implementation Plans:}
\begin{itemize}
\item Complete pipelined architecture implementation with optimized CPU processing stages
\item Implement comprehensive DPU scheduling system
\item Optimize memory access patterns and buffer management
\item Develop robust testing and validation framework
\end{itemize}
