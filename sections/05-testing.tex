\chapter{Testing}\label{chap:testing}

\section{Testing Strategy Overview}\label{sec:testing-overview}

Comprehensive testing validated performance objectives (<16.6ms per frame, 99.8\% accuracy) through early and continuous validation of pipeline stages, memory management, and DPU scheduling. Challenges included FPGA hardware testing, pipelined thread coordination, and balancing speed with accuracy. Testing schedule: weeks 1-2 (unit), 3-4 (integration), 5-6 (system), 7-8 (stress), 9-10 (final validation).

\section{Unit Testing}\label{sec:unit-testing}

\subsection{Unit Testing}\label{subsec:unit-testing-details}

Feature map testing validated consistency between unified and scheduled implementations through layer-by-layer comparison using 80-20 dataset split. Algorithm testing verified fair DPU access, periodic data collection deadlines, and scheduling robustness. System coordination validated timing requirements, resource utilization, and stability. Success criteria: 100\% feature map consistency, zero missed deadlines, >30\% efficiency improvement.

\section{Interface Testing}\label{sec:interface-testing}

\subsection{Interface Testing}\label{subsec:interface-testing-details}

Tested scheduler-algorithm interfaces (request handling, preemption, fairness), DPU-segmentation interface (resource utilization, feature map integrity, context switching overhead), memory management (access patterns, contention minimization, protection), and thread coordination (resource allocation, priority escalation, synchronization). Test cases validated data processing accuracy, resource management stability, and periodic collection deadline compliance.

\section{System Testing}\label{sec:system-testing}

\subsection{System Testing}\label{subsec:system-testing-details}

Continuous running test~\cite{smith2023eyetracking} maintained 16.6ms intervals for 30+ minutes. Lighting test maintained >98\% accuracy across varying conditions. Stress test verified stability under memory/processing limits. Long-term test (24+ hours) confirmed no crashes or degradation. Metrics: >60 FPS, >98\% accuracy, <16.6ms latency, memory usage, and stability.

\section{Regression Testing}\label{sec:regression-testing}

\section{Regression Testing}\label{sec:regression-testing-details}

Automated regression tests verify performance (test runner with history), accuracy (dataset with ground truth), and resource usage (Vitis AI Profiler~\cite{amd2023vitis}) tracking runtime, DPU usage, memory, and thread timing.

\section{Integration and Performance Testing}\label{sec:integration-performance}

Multi-algorithm integration verified conflict-free operation, priority escalation, and end-to-end data flow. Hardware-software integration tested camera reliability, DPU scheduling, and memory management. Benchmarking compared optimized vs. baseline performance and validated efficiency improvements. Stress testing evaluated maximum load, memory constraints, and extended duration stability.

\section{Quality Assurance}\label{sec:quality-assurance}

Testing methodology follows IEEE 3129-2023~\cite{ieee3129-2023} (robustness testing across lighting, stress, and stability conditions) and IEEE 2802-2022~\cite{ieee2802-2022} (performance and safety evaluation for AI medical devices). Documentation includes test cases, performance baselines, issue tracking, and regression test evolution.
